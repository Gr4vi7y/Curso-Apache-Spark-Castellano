{"cells": [{"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "nbgrader": {"cell_type": "markdown", "checksum": "7f949b17b8f2814baa87c674deefe4d3", "grade": false, "grade_id": "cell-f8987996be9f1238", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": "# La organizaci\u00f3n Kiva de pr\u00e9stamos entre particulares\n\n### Disponible en Kaggle en:\nhttps://www.kaggle.com/kiva/data-science-for-good-kiva-crowdfunding/version/5\n\nEl conjunto de datos elegido recoge estad\u00edsticas de Kiva entre 2014 y 2017. Kiva abre un nuevo mundo de oportunidades para los menos favorecidos y nos permite a cualquiera de nosotros convertirnos en superh\u00e9roes. Se trata de una organizaci\u00f3n sin \u00e1nimo de lucro que ofrece peque\u00f1os pr\u00e9stamos para ayudar a las comunidades desatendidas que no tienen acceso a los servicios bancarios normales. Proporciona una plataforma y une a personas que est\u00e9n dispuestas a prestar, un m\u00ednimo de 25 d\u00f3lares, y prestatarios que expongan sus necesidades, la finalidad del dinero y las condiciones de devoluci\u00f3n,  porque no es una donaci\u00f3n, es un pr\u00e9stamo.\n\nAl crear este servicio, Kiva habilita una soluci\u00f3n que desbloquea capital para todos y mantiene un inter\u00e9s financiero muy bajo para los prestatarios. Por otro lado, permite que cualquiera sea parte de la soluci\u00f3n y brinda a las personas un amplio abanico de opciones para elegir qui\u00e9n, d\u00f3nde, cu\u00e1nto y para qu\u00e9 sector desea ayudar."}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "nbgrader": {"cell_type": "markdown", "checksum": "9a6b4dc108ddf890c659e33701965428", "grade": false, "grade_id": "cell-f74d7bfd01811789", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": "### Variables y significado"}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "nbgrader": {"cell_type": "markdown", "checksum": "ea569f4edabc5d7306f8ee2b35adc403", "grade": false, "grade_id": "cell-9cfb34982bd4eb04", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": "Las variables utilizadas para describir cada pr\u00e9stamo son:\n\n\n* id: ID \u00fanico para pr\u00e9stamo\n* funding_amount: la cantidad desembolsada por Kiva al agente de campo (USD)\n* loan_amount: la cantidad desembolsada por el agente de campo al prestatario (USD)\n* country_code: c\u00f3digo ISO del pa\u00eds en el que se desembols\u00f3 el pr\u00e9stamo\n* activity: Categor\u00eda m\u00e1s granular\n* sector: Categor\u00eda de alto nivel\n* use: Uso exacto del monto del pr\u00e9stamo\n* country: Nombre completo del pa\u00eds en el que se desembols\u00f3 el pr\u00e9stamo\n* region: Nombre completo de la regi\u00f3n dentro del pa\u00eds\n* currency: La moneda en que se desembols\u00f3 el pr\u00e9stamo\n* partner_id: ID de la organizaci\u00f3n asociada\n* posted_time: Hora a la que el agente de campo (intermediario) publica el pr\u00e9stamo en Kiva\n* disbursed_time: Hora en que el agente de campo (intermediario) entrega el pr\u00e9stamo al beneficiario\n* funded_time: El momento en que el pr\u00e9stamo publicado en Kiva es financiado por los prestamistas por completo\n* term_in_months: La duraci\u00f3n por la cual el pr\u00e9stamo se desembols\u00f3 en meses\n* lender_count: El n\u00famero total de prestamistas que contribuyeron a este pr\u00e9stamo.\n* tags: Etiquetas para describir el caso espec\u00edfico\n* borrower_genders: letras M, F separadas por comas, donde cada instancia representa un solo hombre / mujer en el grupo\n* repayment_interval: Estado de pago\n* date: fecha en la base de datos de esta operaci\u00f3n."}, {"cell_type": "markdown", "metadata": {}, "source": "**Nombre completo del alumno:**  "}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "nbgrader": {"cell_type": "markdown", "checksum": "76dc5b331cac3113e9e77522358617bf", "grade": false, "grade_id": "cell-b4f9c37a2b92d2e6", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": "**INSTRUCCIONES**: en cada celda debes responder a la pregunta formulada, asegur\u00e1ndote de que el resultado queda guardado en la(s) variable(s) que por defecto vienen inicializadas a `None`. No se necesita usar variables intermedias, pero puedes hacerlo siempre que el resultado final del c\u00e1lculo quede guardado exactamente en la variable que ven\u00eda inicializada a None (debes reemplazar None por la secuencia de transformaciones necesarias, pero nunca cambiar el nombre de esa variable). **No olvides borrar la l\u00ednea *raise NotImplementedError()* de cada celda cuando hayas completado la soluci\u00f3n de esa celda y quieras probarla**.\n\nDespu\u00e9s de cada celda evaluable ver\u00e1s una celda con c\u00f3digo. Ejec\u00fatala (no modifiques su c\u00f3digo) y te dir\u00e1 si tu soluci\u00f3n es correcta o no. En caso de ser correcta, se ejecutar\u00e1 correctamente y no mostrar\u00e1 nada, pero si no lo es mostrar\u00e1 un error. Adem\u00e1s de esas pruebas, se realizar\u00e1n algunas m\u00e1s (ocultas) a la hora de puntuar el ejercicio, pero evaluar dicha celda es un indicador bastante fiable acerca de si realmente has implementado la soluci\u00f3n correcta o no. Aseg\u00farate de que, al menos, todas las celdas indican que el c\u00f3digo es correcto antes de enviar el notebook terminado."}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "nbgrader": {"cell_type": "markdown", "checksum": "9d51114ba5e01cc1f49401e7ec3fec2e", "grade": false, "grade_id": "cell-69ec0993eeaff3ac", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": "### Sobre el dataset kiva_loans.csv se pide:"}, {"cell_type": "markdown", "metadata": {}, "source": "**(1 punto)** Ejercicio 1\n\n* Leerlo **sin intentar** que Spark infiera el tipo de dato de cada columna\n* Puesto que existen columnas que contienen una coma enmedio del valor, en esos casos los valores vienen entre comillas dobles. Spark ya contempla esta posibilidad y puede leerlas adecuadamente **si al leer le indicamos las siguientes opciones adicionales** adem\u00e1s de las que ya sueles usar: `.option(\"quote\", \"\\\"\").option(\"escape\", \"\\\"\")`.\n* Aseg\u00farate de que las **filas que no tienen el formato correcto sean descartadas**, indicando tambi\u00e9n la opci\u00f3n `mode` con el valor `DROPMALFORMED` como vimos en clase.\n* Crear un nuevo DF `kivaRawNoNullDF` en el que se hayan eliminado todas las filas que tengan alg\u00fan valor nulo en cualquier columna **excepto en la columna tags**, que no ser\u00e1 relevante para el an\u00e1lisis y por tanto podemos ignorar sus valores nulos y mantener dichas filas."}, {"cell_type": "code", "execution_count": 3, "metadata": {"deletable": false, "nbgrader": {"cell_type": "code", "checksum": "5dd7b5af2400b59ee2155e84fbd2bc1b", "grade": false, "grade_id": "read_csv", "locked": false, "schema_version": 3, "solution": true, "task": false}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- id: string (nullable = true)\n |-- funded_amount: string (nullable = true)\n |-- loan_amount: string (nullable = true)\n |-- activity: string (nullable = true)\n |-- sector: string (nullable = true)\n |-- use: string (nullable = true)\n |-- country_code: string (nullable = true)\n |-- country: string (nullable = true)\n |-- region: string (nullable = true)\n |-- currency: string (nullable = true)\n |-- partner_id: string (nullable = true)\n |-- posted_time: string (nullable = true)\n |-- disbursed_time: string (nullable = true)\n |-- funded_time: string (nullable = true)\n |-- term_in_months: string (nullable = true)\n |-- lender_count: string (nullable = true)\n |-- tags: string (nullable = true)\n |-- borrower_genders: string (nullable = true)\n |-- repayment_interval: string (nullable = true)\n |-- date: string (nullable = true)\n\n"}], "source": "# L\u00cdNEA EVALUABLE, NO RENOMBRAR LAS VARIABLES\nfrom pyspark.sql import functions as F\n\nkivaRawDF = spark.read\\\n                 .option(\"header\", \"true\")\\\n                 .option(\"inferSchema\", \"false\")\\\n                 .option(\"quote\", \"\\\"\").option(\"escape\", \"\\\"\")\\\n                 .option(\"mode\", \"DROPMALFORMED\")\\\n                 .csv(\"gs://modulo_hadoopspark/data/ModeloD kiva_loans.csv\")\n\nkivaRawDF.printSchema()\n\n# Descomentar estas l\u00edneas para calcular la lista de columnas que s\u00ed deben tenerse en cuenta para quitar nulos. Despu\u00e9s\n# tendr\u00e1s que utilizar dicha lista en la operaci\u00f3n que elimina los nulos\ncolumnasExceptoTags = kivaRawDF.columns\ncolumnasExceptoTags.remove(\"tags\")\nkivaRawNoNullDF = kivaRawDF.na.drop(subset=columnasExceptoTags)"}, {"cell_type": "code", "execution_count": 4, "metadata": {"deletable": false, "editable": false, "nbgrader": {"cell_type": "code", "checksum": "188c34c4f8b30b2afe579969e84c4636", "grade": true, "grade_id": "read_csv_test", "locked": true, "points": 1, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": "from pyspark.sql.types import DoubleType\nassert(kivaRawNoNullDF.count() == 574115)"}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "nbgrader": {"cell_type": "markdown", "checksum": "d2298099dcc1ad4426ab91db020be936", "grade": false, "grade_id": "cell-b90f5b934eda250e", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": "**(1 punto)** Ejercicio 2\n\n* Las columnas `posted_time` y `disbursed_time` son en realidad instantes de tiempo que Spark deber\u00eda procesar como timestamp. Partiendo de `kivaRawNoNullDF`, reemplaza **ambas columnas** por su versi\u00f3n convertida a timestamp, utilizando `withColumn` con el mismo nombre de cada columna, y donde el nuevo valor de la columna viene dado por el siguiente c\u00f3digo:\n\n        F.from_unixtime(F.unix_timestamp('nombreColumna', 'yyyy-MM-dd HH:mm:ssXXX')).cast(\"timestamp\"))\n\n* Adem\u00e1s, convierte a `DoubleType` la columna `loan_amount` y a `IntegerType` la columna `term_in_months`.\n\n* El DF resultante de todas estas operaciones debe quedar almacenado en la variable `kivaDF`, **cacheado**.\n"}, {"cell_type": "code", "execution_count": 5, "metadata": {"deletable": false, "nbgrader": {"cell_type": "code", "checksum": "ca99506697f9a967d82bac2f35307d4d", "grade": false, "grade_id": "convert_timestamp", "locked": false, "schema_version": 3, "solution": true, "task": false}}, "outputs": [{"data": {"text/plain": "DataFrame[id: string, funded_amount: string, loan_amount: double, activity: string, sector: string, use: string, country_code: string, country: string, region: string, currency: string, partner_id: string, posted_time: timestamp, disbursed_time: timestamp, funded_time: string, term_in_months: int, lender_count: string, tags: string, borrower_genders: string, repayment_interval: string, date: string]"}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": "import pyspark.sql.functions as F\nfrom pyspark.sql.types import DoubleType, IntegerType\n# L\u00cdNEAS EVALUABLES, NO RENOMBRAR LAS VARIABLES\nkivaDF = kivaRawNoNullDF.withColumn(\"posted_time\", F.from_unixtime(F.unix_timestamp('posted_time', 'yyyy-MM-dd HH:mm:ssXXX')).cast(\"timestamp\"))\\\n                        .withColumn(\"disbursed_time\", F.from_unixtime(F.unix_timestamp('disbursed_time', 'yyyy-MM-dd HH:mm:ssXXX')).cast(\"timestamp\"))\\\n                        .withColumn(\"loan_amount\", F.col(\"loan_amount\").cast(DoubleType()))\\\n                        .withColumn(\"term_in_months\", F.col(\"term_in_months\").cast(IntegerType()))\n\nkivaDF.cache()"}, {"cell_type": "code", "execution_count": 6, "metadata": {"deletable": false, "editable": false, "nbgrader": {"cell_type": "code", "checksum": "8bf617944fb4248cb79632c80062746c", "grade": true, "grade_id": "convert_timestamp_tests", "locked": true, "points": 1, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": "typesDict = dict(kivaDF.dtypes)\nassert(typesDict[\"posted_time\"] == \"timestamp\") \nassert(typesDict[\"disbursed_time\"] == \"timestamp\") \nassert(typesDict[\"loan_amount\"] == \"double\") \nassert(typesDict[\"term_in_months\"] == \"int\")\ncnt_cond = lambda cond: F.sum(F.when(cond, 1).otherwise(0))\nnullsRow = kivaDF.select(cnt_cond(F.col(\"posted_time\").isNull()).alias(\"posted_nulls\"),\n              cnt_cond(F.col(\"disbursed_time\").isNull()).alias(\"disbursed_nulls\")).head()\nassert(nullsRow.posted_nulls == 0)\nassert(nullsRow.disbursed_nulls == 0)"}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "nbgrader": {"cell_type": "markdown", "checksum": "1e93f385f93838abff6492567725cfba", "grade": false, "grade_id": "cell-fc88821f19453a51", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": "**(2 puntos)** Ejercicio 3\n\nPartiendo de `kivaDF`:\n\n* Primero, a\u00f1ade una nueva columna `dias_desembolso` que contenga el n\u00famero de d\u00edas que han pasado entre la fecha en que los prestamistas aceptaron financiar un proyecto, y la fecha en que el agente de campo entreg\u00f3 los fondos al beneficiario. Para ello, utiliza `withColumn` en combinaci\u00f3n con la funci\u00f3n `F.datediff(\"colFuturo\", \"colPasado\")`\n* De manera an\u00e1loga, a\u00f1ade otra nueva columna `dias_aceptacion` que contenga el n\u00famero de d\u00edas entre el anuncio de la necesidad de pr\u00e9stamo y la aceptaci\u00f3n de financiarlo por parte de alg\u00fan prestamista.\n* Reemplazar la columna `sector` por otra en la que se hayan traducido las categor\u00edas \"Education\" por \"Educacion\" (sin tilde para evitar posibles problemas) y \"Agriculture\" por \"Agricultura\", dejando como est\u00e1n el resto de categor\u00edas. **La sustituci\u00f3n no debe tener m\u00e1s que tres casos**: uno para cada categor\u00eda que vamos a reemplazar, y un tercero para el resto de categor\u00edas, que deben quedarse como estaban.\n* El resultado debe quedar guardado en la variable `kivaTiemposDF`."}, {"cell_type": "code", "execution_count": 7, "metadata": {"deletable": false, "nbgrader": {"cell_type": "code", "checksum": "5ca4098e1a7f6a6f74ba37e09dc7fafe", "grade": false, "grade_id": "aniade_tiempos", "locked": false, "schema_version": 3, "solution": true, "task": false}}, "outputs": [], "source": "# L\u00cdNEA EVALUABLE, NO RENOMBRAR VARIABLES\nimport pyspark.sql.functions as F\n\nkivaTiemposDF = kivaDF.withColumn(\"dias_desembolso\", F.datediff(\"disbursed_time\", \"funded_time\"))\\\n                      .withColumn(\"dias_aceptacion\", F.datediff(\"funded_time\", \"posted_time\"))\\\n                      .withColumn(\"sector\", F.when((F.col(\"sector\") == \"Education\"), \"Educacion\")\\\n                                             .when((F.col(\"sector\") == \"Agriculture\"), \"Agricultura\")\\\n                                             .otherwise(F.col(\"sector\")))\n"}, {"cell_type": "code", "execution_count": 8, "metadata": {"deletable": false, "editable": false, "nbgrader": {"cell_type": "code", "checksum": "dcadcc48648f84d47868016a5a1b2176", "grade": true, "grade_id": "aniade_tiempos_test", "locked": true, "points": 2, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": "assert(kivaTiemposDF.where(\"sector == 'Agricultura'\").count() == 157003)\nassert(kivaTiemposDF.where(\"sector == 'Educacion'\").count() == 28417)\n# Comprobamos que las 13 restantes se mantienen sin cambios\nassert(kivaTiemposDF.groupBy(\"sector\").count().join(kivaDF.groupBy(\"sector\").count(), [\"sector\", \"count\"]).count() == 13)"}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "nbgrader": {"cell_type": "markdown", "checksum": "79185ceef173a0104b5f923e4bde05a0", "grade": false, "grade_id": "cell-a71a6b17b1e0d613", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": "**(3 puntos)** Ejercicio 4\n\nPartiendo de `kivaTiemposDF`, crear un nuevo DataFrame llamado `kivaAgrupadoDF` que tenga:\n\n* Tantas filas como **pa\u00edses (`country`; no usar el c\u00f3digo de pa\u00eds)**, y tantas columnas como **sectores** (cada una llamada como el sector) m\u00e1s una (la columna del pa\u00eds, que debe aparecer en primer lugar). En cada celda deber\u00e1 ir el n\u00famero **medio (redondeado a 2 cifras decimales)** de d\u00edas transcurridos en ese pa\u00eds y sector *entre la fecha en que se anuncia la necesidad de pr\u00e9stamo y la fecha en la que un prestamista acepta financiarlo*. Esta columna ha sido calculada en la celda precedente.\n* Despu\u00e9s de esto, a\u00f1adir una columna adicional `transcurrido_global` con el n\u00famero **medio (redondeado a 2 cifras decimales) de d\u00edas transcurridos en cada pa\u00eds** entre ambas fechas *sin tener en cuenta el sector*. Cada fila tendr\u00e1 la media de las 15 columnas del apartado anterior.\n* Por \u00faltimo, ordenar el DF resultante **descendentemente** en base al tiempo medio global, `transcurrido_global`. El DF resultado de la ordenaci\u00f3n debe ser almacenado en la variable `kivaAgrupadoDF`. \n\nPISTA: utiliza el m\u00e9todo `pivot` con el sector para el primer apartado, envolviendo a la funci\u00f3n de agregaci\u00f3n con la funci\u00f3n `F.round`, es decir, `F.round(F.funcionAgregacion(....), 2)`, y `withColumn` con una operaci\u00f3n aritm\u00e9tica entre columnas en el segundo. **No debe utilizarse la funci\u00f3n `when`** ya que Spark es capaz de hacer directamente aritm\u00e9tica entre objetos columna. La operaci\u00f3n aritm\u00e9tica tambi\u00e9n debe estar envuelta por round: `F.round(op. aritm\u00e9tica entre objetos columna, 2)`."}, {"cell_type": "code", "execution_count": 9, "metadata": {"deletable": false, "nbgrader": {"cell_type": "code", "checksum": "396a2289c6c4fa8c5de5540783d27942", "grade": false, "grade_id": "tiempos_medios", "locked": false, "schema_version": 3, "solution": true, "task": false}}, "outputs": [], "source": "# L\u00cdNEA EVALUABLE, NO RENOMBRAR VARIABLES\nkivaAgrupadoDF1 = kivaTiemposDF.groupBy(F.col(\"country\")).pivot(\"sector\")\\\n                                                        .agg(F.round((F.mean(F.col(\"dias_aceptacion\"))), 2))\n                                                    \n\nkivaAgrupadoDF = kivaAgrupadoDF1.withColumn(\"transcurrido_global\", \\\n            F.round(((sum(kivaAgrupadoDF1[col] for col in kivaAgrupadoDF1.columns[1:]))/ (len(kivaAgrupadoDF1.columns) - 1)), 2))\\\n            .orderBy(\"transcurrido_global\", ascending=False)                                                    "}, {"cell_type": "code", "execution_count": 10, "metadata": {"deletable": false, "editable": false, "nbgrader": {"cell_type": "code", "checksum": "93ebd38f5b390fbfbd89be06a50c6282", "grade": true, "grade_id": "tiempos_medios_test", "locked": true, "points": 3, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": "r1 = kivaAgrupadoDF.head()\nassert(r1.country == \"United States\")\nassert((r1.Agricultura - 12.0 < 0.01) | (r1.Agricultura - 12.17 < 0.01))\nassert((r1.Educacion - 15.21 < 0.01) | (r1.Educacion - 15.33 < 0.01))\nassert(r1.Wholesale - 27.5 < 0.01)\nassert((r1.transcurrido_global - 20.94 < 0.01) | (r1.transcurrido_global - 21.04 < 0.01))"}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "nbgrader": {"cell_type": "markdown", "checksum": "31924076e8ce9e4467959d6eef2edcc4", "grade": false, "grade_id": "cell-c5ec05706eccd480", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": "**(3 puntos)** Ejercicio 5\n\nPartiendo de nuevo de `kivaTiemposDF`, a\u00f1adir las siguientes columnas:\n\n* Primero, tres columnas adicionales llamadas `transc_medio`, `transc_min`, `transc_max` que contengan, respectivamente, **el n\u00famero de d\u00edas medio, m\u00ednimo y m\u00e1ximo transcurrido para proyectos de ese mismo pa\u00eds y ese mismo sector** entre la fecha en que se postea la necesidad de pr\u00e9stamo y la fecha en la que alguien acepta financiarlo (es decir, la columna `dias_aceptacion` calculada antes y utilizada tambi\u00e9n en la celda anterior). Es decir, queremos una columna extra para que podamos tener, junto a cada pr\u00e9stamo, informaci\u00f3n agregada de los pr\u00e9stamos similares, entendidos como aquellos del mismo pa\u00eds y del mismo sector. **No se debe utilizar JOIN sino solo funciones de ventana**.\n* Finalmente, crear otra columna adicional `diff_dias` que contenga la **diferencia en d\u00edas entre los d\u00edas que transcurrieron en este proyecto y la media de d\u00edas de los proyectos similares** (calculada en el apartado anterior). Deber\u00eda ser lo primero menos lo segundo, de forma que un n\u00famero positivo indica que este pr\u00e9stamo tard\u00f3 m\u00e1s d\u00edas en ser aceptado que la media de d\u00edas de este pa\u00eds y sector, y un n\u00famero negativo indica lo contrario. El resultado debe obtenerse aplicando operaciones aritm\u00e9ticas con columnas existentes, **sin utilizar `when`**.\n* El DF resultante con las 4 columnas nuevas que hemos a\u00f1adido debe quedar almacenado en la variable `kivaExtraInfoDF`."}, {"cell_type": "code", "execution_count": 11, "metadata": {"deletable": false, "nbgrader": {"cell_type": "code", "checksum": "7781e45de12eaece0b66e4eb898e2b0b", "grade": false, "grade_id": "ventana", "locked": false, "schema_version": 3, "solution": true, "task": false}}, "outputs": [], "source": "# L\u00cdNEA EVALUABLE, NO RENOMBRAR VARIABLES\nfrom pyspark.sql import Window\n\nwindowPaisSector = Window().partitionBy(\"country\", \"sector\")\nkivaExtraInfoDF = kivaTiemposDF.withColumn(\"transc_medio\", F.mean(\"dias_aceptacion\").over(windowPaisSector))\\\n                               .withColumn(\"transc_min\", F.min(\"dias_aceptacion\").over(windowPaisSector))\\\n                               .withColumn(\"transc_max\", F.max(\"dias_aceptacion\").over(windowPaisSector))\\\n                               .withColumn(\"diff_dias\",  ((F.datediff(\"funded_time\", \"posted_time\")) - F.col(\"dias_aceptacion\")))\n                                           "}, {"cell_type": "code", "execution_count": 12, "metadata": {"deletable": false, "editable": false, "nbgrader": {"cell_type": "code", "checksum": "844f128aa6e789cd3660a00ab0159b56", "grade": true, "grade_id": "ventana_test", "locked": true, "points": 3, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": "r = kivaExtraInfoDF.where(\"id = '658540'\").head()\nassert(r.country == 'Burkina Faso')\nassert(r.transc_medio - 11.02 < 0.05)\nassert(r.dias_aceptacion == 35)\nassert(r.diff_dias - 24.0 < 0.001)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.12"}}, "nbformat": 4, "nbformat_minor": 4}